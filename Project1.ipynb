{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow LSTM Multi-label Tag Prediction\n",
    "\n",
    "This notebook demonstrates an end-to-end pipeline for predicting the top 10 Stack Overflow tags using an LSTM model. It is optimized for large datasets and ready for GitHub submission."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, hamming_loss, accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import os\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Filtering\n",
    "- Load questions and tags\n",
    "- Filter for top 10 tags\n",
    "- Keep only relevant questions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load data (update paths as needed)\n",
    "questions = pd.read_csv('Questions.csv', usecols=['Id', 'Title', 'Body'])\n",
    "tags = pd.read_csv('Tags.csv')\n",
    "\n",
    "# Find top 10 tags\n",
    "top_tags = tags['Tag'].value_counts().head(10).index.tolist()\n",
    "filtered_tags = tags[tags['Tag'].isin(top_tags)]\n",
    "question_ids = filtered_tags['Id'].unique()\n",
    "filtered_questions = questions[questions['Id'].isin(question_ids)].copy()\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing\n",
    "- Remove HTML, lowercase, remove non-alphabetic chars\n",
    "- Combine title and body"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def strip_html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").get_text(separator=\" \") if pd.notnull(text) else \"\"\n",
    "\n",
    "filtered_questions['Title'] = filtered_questions['Title'].astype(str)\n",
    "filtered_questions['Body'] = filtered_questions['Body'].astype(str)\n",
    "filtered_questions['Body_no_html'] = filtered_questions['Body'].map(strip_html)\n",
    "\n",
    "filtered_questions['Cleaned_Title'] = (\n",
    "    filtered_questions['Title']\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^a-z\\s]', ' ', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "filtered_questions['Cleaned_Body'] = (\n",
    "    filtered_questions['Body_no_html']\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^a-z\\s]', ' ', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "filtered_questions['Combined_Text'] = (\n",
    "    filtered_questions['Cleaned_Title'] + \" \" + filtered_questions['Cleaned_Body']\n",
    ")\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-label Target Preparation\n",
    "- Group tags per question\n",
    "- Binarize for multi-label"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tags_per_question = (\n",
    "    filtered_tags.groupby('Id')['Tag']\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "tags_per_question['Tag'] = tags_per_question['Tag'].apply(\n",
    "    lambda tag_list: [tag for tag in tag_list if tag in top_tags]\n",
    ")\n",
    "tags_per_question = tags_per_question[tags_per_question['Tag'].map(len) > 0]\n",
    "questions_targets = pd.merge(\n",
    "    filtered_questions, tags_per_question, on='Id', how='inner'\n",
    ")\n",
    "mlb = MultiLabelBinarizer(classes=top_tags)\n",
    "tag_matrix = mlb.fit_transform(questions_targets['Tag'])\n",
    "tag_df = pd.DataFrame(tag_matrix, columns=mlb.classes_, index=questions_targets.index)\n",
    "final_df = pd.concat([questions_targets.reset_index(drop=True), tag_df], axis=1)\n",
    "final_df = final_df.drop(columns=['Tag'])"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenization and Padding for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "texts = final_df['Combined_Text'].astype(str).tolist()\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "tag_columns = top_tags\n",
    "y = final_df[tag_columns].values.astype(np.float32)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LSTM Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = Sequential([\n",
    "    Embedding(max_words, 64, input_length=max_len),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(tag_columns), activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "print(classification_report(y_val, y_pred, target_names=tag_columns))\n",
    "print(f\"Hamming Loss: {hamming_loss(y_val, y_pred):.4f}\")\n",
    "print(f\"Subset Accuracy: {accuracy_score(y_val, y_pred):.4f}\")"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model and Preprocessing Objects"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.save('stack_overflow_lstm_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "with open('mlb.pkl', 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: Predict tags for a new question\n",
    "def predict_tags(text, max_len=200):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_len)\n",
    "    pred = model.predict(padded)\n",
    "    tags = mlb.inverse_transform((pred > 0.5).astype(int))\n",
    "    return tags\n",
    "\n",
    "example = \"How do I connect to SQL Server using C#?\"\n",
    "print(\"Predicted tags:\", predict_tags(example))"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "- This notebook provides a full pipeline for multi-label tag prediction using LSTM.\n",
    "- Artifacts are saved for reproducibility and deployment.\n",
    "- Ready for GitHub submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
